集合类存放于 Java.util 包中，主要有 3 种：set(集）、list(列表包含 Queue）和 map(映射)。

 Collection：Collection 是集合 List、Set、Queue 的最基本的接口。

 Iterator：迭代器，可以通过迭代器遍历集合中的数据。

 Map：是映射表的基础接口。

------



## List

List 是有序的 Collection。Java List 一共三个实现类：

分别是 ArrayList、Vector 和 LinkedList。

#### ArrayList

ArrayList 是容量可变列表，使用数组实现，扩容时会创建更大的数组，把原有数组复制到新数组。支持对元素的随机访问，但插入与删除速度慢。因此，它适合随机查找和遍历，不适合插入和删除。ArrayList 实现了 RandomAcess 接口，如果类实现了该接口，使用索引遍历比迭代器更快。

elementData 是 ArrayList 的数据域，被 transient 修饰，序列化时调用 `writeObject` 写入流，反序列化时调用 `readObject` 重新赋值到新对象的 elementData。原因是 elementData 容量通常大于实际存储元素的数量，所以只需发送真正有值的元素。

size 是当前实际大小，小于等于 elementData 的大小。

modCount 记录了 ArrayList 结构性变化的次数，继承自 AbstractList。expectedModCount 是迭代器初始化时记录的 modCount 值，每次访问新元素时都会检查 modCount 是否等于 expectedModCount，不等将抛出异常。这种机制叫 fail-fast，所有集合类都有。

#### Vector 

Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢。

#### LinkedList

LinkedList 本质是双向链表，与 ArrayList 相比增删速度更快，但随机访问慢。除继承 AbstractList 外还实现了 Deque 接口，该接口具有队列和栈的性质。成员变量被 transient 修饰，原理和 ArrayList 类似。

包含三个重要的成员：size、first 和 last。size 是双向链表中节点的个数，first 和 last 分别指向首尾节点。

优点：可以将零散的内存单元通过附加引用的方式关联起来，形成按链路顺序查找的线性结构，内存利用率高。

------



## Set

Set 注重独一无二的性质,该体系集合用于存储无序(存入和取出的顺序不一定相同)元素，**值不能重复**。对象的相等性本质是对象hashCode 值（java 是依据对象的内存地址计算出的此序号）判断的，如果想要让两个不同的对象视为相等的，就必须覆盖 Object 的 hashCode 方法和 equals 方法。

#### HashSet 

HashSet 通过 HashMap 实现，HashMap 的 Key 即 HashSet 存储的元素，所有 Key 都使用相同的 Value ，一个 Object 类型常量。使用 Key 保证元素唯一性，但不保证有序性。HashSet 判断元素是否相同时，对于包装类型直接按值比较，对于引用类型先比较 hashCode，不同则代表不是同一个对象，相同则比较 equals，都相同才是同一个对象。

#### LinkedHashSet 

LinkedHashSet 继承自 HashSet，通过 LinkedHashMap 实现，使用双向链表维护元素插入顺序。

#### TreeSet 

TreeSet 通过 TreeMap 实现的，添加元素到集合时按照比较规则将其插入合适的位置，保证插入后的集合仍然有序。

------



## Map

#### TreeMap

TreeMap 基于红黑树实现，增删改查的平均和最差时间复杂度均为 O(log~~n~~) ，最大特点是 Key 有序。Key 必须实现 Comparable 接口或 Comparator 接口，所以 Key 不允许为 null。

TreeMap 依靠 Comparable 或 Comparator 排序，如果实现了 Comparator 就会优先使用 `compare` 方法，否则使用 Comparable 的 `compareTo` 方法，两者都不满足会抛出异常。

TreeMap 通过 `put` 和 `deleteEntry` 实现增加和删除树节点。插入新节点的规则有三个：① 需要调整的新节点总是红色的。② 如果插入新节点的父节点是黑色的，不需要调整。③ 如果插入新节点的父节点是红色的，由于红黑树不能出现相邻红色，进入循环判断，通过重新着色或左右旋转来调整。

------

#### HashMap 

JDK8 前底层使用数组加链表，JDK8 改为数组加链表/红黑树，节点从 Entry 变为 Node。主要成员变量包括 table 数组、元素数量 size、加载因子 loadFactor。

table 数组记录 HashMap 的数据，每个下标对应一条链表，所有哈希冲突的数据都会被存放到同一条链表，Node/Entry 节点包含四个成员变量：key、value、next 和 hash。

数据以键值对的形式存在，键对应的 hash 值用来计算数组下标，如果两个元素 key 的 hash 值一样，就会发生哈希冲突，被放到同一个链表上，为使查询效率尽可能高，键的 hash 值要尽可能分散。

默认初始化容量为 16，扩容容量必须是 2 的幂次方、最大容量为 1<< 30 、默认加载因子为 0.75。

------

##### Hash冲突

1、 什么是hash表

根据设定的哈希函数H(key)和处理冲突的方法将一组关键字映像到一个有限的连续的地址集（区间）上，并以关键字在地址集中的“像”作为记录在表中的存储位置，这种表便称为哈希表，这一映像过程称为哈希造表或者散列，所得的存储位置称哈希地址或散列地址。

2、 hash冲突

对应不同的关键字可能获得相同的hash地址，即 key1≠key2，但是f(key1)=f(key2)。这种现象就是冲突，而且这种冲突只能尽可能的减少，不能完全避免。因为哈希函数是从关键字集合和地址集合的映像，通常关键字集合比较大，而地址集合的元素仅为哈希表中的地址值。

3、 处理冲突的方法。

通常用的冲突处理方法有以下几种：

(1)、**开放定址法**

![[公式]](https://www.zhihu.com/equation?tex=H_i%3D%28H%28key%29%2Bd_i+%29MOD+m++++i%3D1%2C2%2C3%2C%E2%80%A6%E2%80%A6%2Ck+%28k%3C%3D+m-1%29)

其中H(key)为hash函数，m为哈希表的长度， ![[公式]](https://www.zhihu.com/equation?tex=d_i) 为增量序列，其取值有三种防止：

a、线性探测再散列：

​											 ![[公式]](https://www.zhihu.com/equation?tex=d_i%3D1%EF%BC%8C2%EF%BC%8C3%EF%BC%8C%E2%80%A6%EF%BC%8Cm+%E2%80%93+1%EF%BC%8C)

b、二次探测再散列：

![[公式]](https://www.zhihu.com/equation?tex=d_i%3D1%5E2%EF%BC%8C-1%5E2%EF%BC%8C2%5E2%EF%BC%8C-2%5E2%EF%BC%8C3%5E2%EF%BC%8C-3%5E2%EF%BC%8C%E2%80%A6..%C2%B1k%5E2+%2C+k%3C%3D+m%2F2%EF%BC%8C)

c、随机探测再散列，

![[公式]](https://www.zhihu.com/equation?tex=d_i%3D%E9%9A%8F%E6%9C%BA%E6%95%B0)

eg：H(key) = key MOD 7，哈希表中已经存在关键字：11，12，15，在插入

关键字18的时候，通过哈希函数的到的地址为4，产生冲突，使用线性探测得到的下一个地址为5，依然冲突，继续探测得到地址6，为空，冲突处理结束，使用二次探测解决冲突第一个地址为5，冲突，再次探测，地址为3，为空，冲突处理结束。

线性探测：



![img](https://pic4.zhimg.com/80/v2-f3e770e012553e23931ecb473045fb57_1440w.png)



二次探测：



![img](https://pic2.zhimg.com/80/v2-b2d192c3f3ba07917241733749f92e6d_1440w.png)



随机探测：



![img](https://pic3.zhimg.com/80/v2-7c97c3e1c907c04257b5748d2749c56e_1440w.png)



从上述可以看出使用线性探测的时候，当i，i+1,位置上都已填有记录的时候，下一个哈希地址为，i，i+1i+2的记录都将填入i+2的地址，者会造成第一个哈希地址不同的记录争夺同一个后继哈希地址的现象称为“二次聚集”，即在处理相同哈希值冲突的时候造成了不同哈希值的冲突，但是在另一个方面可以看出，只要未满使用线性探测总能找到空位置。

（2）、**再哈希法**

![[公式]](https://www.zhihu.com/equation?tex=H_i%3DRH_i+%28key%29%EF%BC%8C+i%3D1%EF%BC%8C2%EF%BC%8C%E2%80%A6%EF%BC%8Ck)

![[公式]](https://www.zhihu.com/equation?tex=RH_i+%28key%29) 都是不同的哈希函数，对产生地址冲突的关键字再次进行哈希计算，获取另一个哈希地址，知道不在产生冲突，这种方法不易产生“二次聚集”，但是增加的计算的时间。

（3）、**链地址法**

每个哈希地址对应的一个线性表，将地址相同的记录按序写入链表，这种处理方法如果收到哈希共计，出现大量的哈希冲突，会导致查询的时间复杂度增长，甚至退化为O(n)，为了提高查询效率我们可以使用跳表或者红黑树等结构替换线性表。

eg: H(key) = key MOD 7，已存在的记录为，0，4，7，9，11，12



![img](https://pic4.zhimg.com/80/v2-be2b772f3e35cfe7d1b89f90c3d3f9e7_1440w.jpg)

（4）、**建立公共溢出区**

顾名思义，在创建哈希表时，同时创建另一个表，将所有发生哈希冲突的记录都存储到溢出表。

------

**JDK8 之前**

![image-20200921143747108](D:\obsidian\JavaNotes\hashMap2.png)

**hash：计算元素 key 的散列值**

① 处理 String 类型时，调用 `stringHash32` 方法获取 hash 值。

② 处理其他类型数据时，提供一个随机值 hashSeed 作为计算初始量，执行异或和无符号右移使 hash 值更加离散。

**indexFor：计算元素下标**

将 hash 值和数组长度-1 进行与操作，保证结果不超过 table 范围。

**get：获取元素的 value 值**

key 为 null，调用 `getForNullKey` 方法：

- size=0 表示链表为空，返回 null。 
- size!=0 说明存在链表，遍历 table[0] 链表，如果找到了 key=null 的节点则返回其 value，否则返回 null。 

key 不为 null，调用 `getEntry` 方法：

- size=0 表示链表为空，返回 null 值。 
- size!=0，首先计算 key 的 hash 值，然后遍历该链表的所有节点，如果节点的 key 和 hash 值都和要查找的元素相同则返回其 Entry 节点。 如果找到了对应的 Entry 节点，调用 `getValue` 方法获取其 value 并返回，否则返回 null。 

**put：添加元素**

key 为 null，直接存入 table[0]。

key 不为 null，计算 key 的 hash 值，调用 `indexFor` 计算元素下标 i，遍历 table[i] 链表：

- key 已存在，更新 value 然后返回旧 value。 
- key 不存在，将 modCount 加 1，调用 `addEntry` 方法增加一个节点并返回 null。 

**resize：扩容数组**

当前容量达到了最大容量，将阈值设置为 Integer 最大值，之后扩容不再触发。

当前容量没达到最大容量，计算新的容量，将阈值设为 `newCapacity x loadFactor` 和 `最大容量 + 1` 的较小值。创建一个容量为 newCapacity 的 Entry 数组，调用 `transfer` 方法将旧数组的元素转移到新数组。

**transfer：转移元素**

遍历旧数组的所有元素，调用 `rehash` 方法判断是否需要哈希重构，如果需要就重新计算元素 key 的 hash 值。

调用 `indexFor` 方法计算元素存放的下标 i，利用头插法将旧数组的元素转移到新数组。

------

**JDK8**

**java8 hashMap结构**

![image-20200921143239633](D:\obsidian\JavaNotes\hashMap.png)

**hash：计算元素 key 的散列值**

如果 key 为 null 返回 0，否则就将 key 的 `hashCode` 方法返回值高低16位异或，让尽可能多的位参与运算，让结果的 0 和 1 分布更加均匀，降低哈希冲突概率。

**put：添加元素**

调用 `putVal` 方法添加元素：

- 如果 table 为空或不存在元素就进行扩容，否则计算元素下标位置，不存在就调用 `newNode` 创建一个节点。 
- 如果存在元素且是链表类型，如果首节点和待插入元素相同，直接更新节点 value。 
- 如果首节点是 TreeNode 类型，调用 `putTreeVal` 方法增加一个树节点，每一次都比较插入节点和当前节点的大小，待插入节点小就往左子树查找，否则往右子树查找，找到空位后执行两个方法：`balanceInsert` 方法，插入节点并调整平衡、`moveRootToFront` 方法，由于调整平衡后根节点可能变化，需要重置根节点。 
- 如果都不满足，遍历链表，根据 hash 和 key 判断是否重复，决定更新 value 还是新增节点。如果遍历到了链表末尾则添加节点，如果达到建树阈值 7，还需要调用 `treeifyBin` 把链表重构为红黑树。 
- 存放元素后将 modCount 加 1，如果 `++size > threshold` ，调用 `resize` 扩容。 

**get ：获取元素的 value 值**

调用 `getNode` 方法获取 Node 节点：

- 如果数组不为空且存在元素，先比较第一个节点和要查找元素，如果相同则直接返回。
- 如果第二个节点是 TreeNode 类型则调用 `getTreeNode` 方法进行查找。
- 都不满足，遍历链表根据 hash 和 key 查找，如果没有找到就返回 null。
- 如果节点不是 null 就返回其 value，否则返回 null。 

**resize：扩容数组**

重新规划长度和阈值，如果长度发生了变化，部分数据节点也要重新排列。

**重新规划长度**

① 如果当前容量 `oldCap > 0` 且达到最大容量，将阈值设为 Integer 最大值，终止扩容。

② 如果未达到最大容量，当 `oldCap << 1` 不超过最大容量就扩大为 2 倍。

③ 如果都不满足且当前扩容阈值 `oldThr > 0`，使用当前扩容阈值作为新容量。

④ 否则将新容量置为默认初始容量 16，新扩容阈值置为 12。

**重新排列数据节点**

① 如果节点为 null 不进行处理。

② 如果节点不为 null 且没有 next 节点，通过节点的 hash 值和 `新容量-1` 进行与运算计算下标存入新的 table 数组。

③ 如果节点为 TreeNode 类型，调用 `split` 方法处理，如果节点数 hc 达到 6 会调用 `untreeify` 方法转回链表。

④ 如果是链表节点，需要将链表拆分为 hash 值超出旧容量的链表和未超出容量的链表。对于`hash & oldCap == 0` 的部分不需要做处理，否则需要放到新的下标位置上，新下标 = 旧下标 + 旧容量。

------

**线程不安全**

JDK7 存在死循环和数据丢失问题。

**数据丢失：**

- **并发赋值被覆盖：** 在 `createEntry` 方法中，新添加的元素放在头部，使元素可以被更快访问，但如果两个线程同时执行到此处，会导致数据覆盖。

- **新表被覆盖：** 如果多线程同时 `resize` ，每个线程都会 new 一个数组，这是线程内的局部对象，线程间不可见。迁移完成后`resize` 的线程会赋值给 table 线程共享变量，可能会覆盖其他线程的操作，在新表中插入的对象都会被丢弃。

  **死循环：** 扩容时 `resize` 调用 `transfer` 使用头插法迁移元素，虽然 newTable 是局部变量，但原先 table 中的 Entry 链表是共享的，问题根源是 Entry 的 next 指针并发修改，某线程还没有将 table 设为 newTable 时用完了 CPU 时间片。

  JDK8 在 `resize` 方法中完成扩容，并改用尾插法，不会产生死循环，但并发下仍可能丢失数据。可用 ConcurrentHashMap 或 `Collections.synchronizedMap` 包装同步集合。

------

#### **ConcurrentHashMap** 

**Segment段**

ConcurrentHashMap 和 HashMap 思路是差不多的，但是因为它支持并发操作，所以要复杂一些。整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个segment。

 **线程安全（Segment继承 ReentrantLock 加锁**）

简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。

**并行度（默认16）**

concurrencyLevel：并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。

------

#### **HashTable（线程安全）**

Hashtable 是遗留类，很多映射的常用功能与 HashMap 类似，不同的是它承自 Dictionary 类，并且是线程安全的，任一时间只有一个线程能写 Hashtable，并发性不如 ConcurrentHashMap，因为 ConcurrentHashMap 引入了分段锁。Hashtable 不建议在新代码中使用，不需要线程安全的场合可以用 HashMap 替换，需要线程安全的场合可以用 ConcurrentHashMap 替换。

------

#### **TreeMap（可排序）**

TreeMap 实现 SortedMap 接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。如果使用排序的映射，建议使用 TreeMap。在使用 TreeMap 时，key 必须实现Comparable 接口或者在构造 TreeMap 传入自定义的Comparator，否则会在运行时抛出 java.lang.ClassCastException 类型的异常。

参考：https://www.ibm.com/developerworks/cn/java/j-lo-tree/index.html

#### **LinkHashMap（记录插入顺序）**

LinkedHashMap 是 HashMap 的一个子类，保存了记录的插入顺序，在用 Iterator 遍历LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。

参考 1：http://www.importnew.com/28263.html

参考 2：http://www.importnew.com/20386.html#comment-648123